#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# python -u -m timeit -v -v -v -v -n 5  -r 3  -s "from program02 import most_frequent_chars" "most_frequent_chars('test01/A.txt')"
# python -u -m timeit -v -v -v -v -n 5  -r 3  -s "from program01 import most_frequent_chars" "most_frequent_chars('test01/A.txt')"
# python -u -m timeit -v -v -v -v -n 5  -r 3  -s "from program01 import most_frequent_chars" "most_frequent_chars('test01/A.txt')"
def most_frequent_chars(filename: str) -> str:
    def analyzer(ws):
        lenght = len
        max_len, len_ws = lenght(max(ws, key=len)), lenght(ws)-1
        two_d, count = [{} for i in range(max_len)], {}

        for position, word in zip(range(len_ws+1), ws):
            lenght_word, index = lenght(word), 0
            while index < lenght_word:
                letter = word[index]
                if two_d[index][letter] is True:
                        if lenght_word-1 > index and two_d[index+1][word[index+1]] is True:
                            letter = word[index+3]
                        else:
                            letter = word[index+1]


                current = two_d[index][letter] = two_d[index].get(letter, 0) + 1
                if current > count[index][0] or (letter < count[index][1] and current == count[index][0]):
                    count[index] = (current, letter)

                if count[index][0] - current > len_ws-position:
                    current = True
                if lenght_word-1 > index and two_d[index+1][word[index+1]] is True:
                    index += 1
                index += 1

        return "".join(x[1] for x in count.values())


    nxt,  workspace = filename, []
    while True:
        workspace = open(nxt, "r", encoding="utf8").read().split() + workspace
        nxt = workspace.pop(0)

        if nxt == filename:
            return analyzer(tuple(workspace))


if __name__ == "__main__":
    # print(most_frequent_chars('test03/woodchuck.txt'))
    datas = (('test02/bullfight.txt', 'poternusakesness'),
            ('test03/woodchuck.txt', 'aanreeaseesable'),
            ('test04/pampers.txt', 'ceeelieessseds'),
            ('test05/avocados.txt','sereeieeesssssncy'),
            ('test06/strums.txt', 'sereeeeesssssssynssm'),
            ('test07/sinew.txt', 'ã™ã²ã³ãšã˜ããœãƒã‘ãã¿ããŠã‚‡ã‡ã©ã¹ã—ã“ã—ã“ã‚Œã‚Œã‚ã­ãã‚ã‚œã·'),
            ('test08/boilings.txt', 'ğŸšğŸğŸ˜¨â™£â˜¢ğŸ¸â€¼ğŸ—»ğŸŒšğŸ¥·ğŸ¯ğŸ½â™¾ğŸ—½ğŸ„âš”ğŸ«“ğŸ˜ ğŸˆğŸª€ğŸâ¡ğŸ¼ğŸ‘©ğŸ˜»ğŸ“¿ğŸŒğŸ•ŒğŸ‘¾ğŸ¤“ğŸ˜šÂ®â‡ğŸ’’ğŸ¦ªğŸ‘’ğŸ’‚â˜ªğŸ¥¡ğŸ¥•'),
            ('test09/meddles.txt', 'á›¢áš¦á›á›¡áš¤áš¬áš¬á›áš¸á›˜áš£áš¢á›œá›¥áš³á›œá›–á›„áš¢á›Šáš¬á›Ÿá›ˆá›…á›áš¹á›¯áš¼á›ášº'),
            ('test10/aileron.txt', 'á› áš£áš»á›áš§á›œá›­ãáš»á›áš­á›ˆášºá›¦áš©á›á›áš½á›ªáš¢áš°áš¯ã²á›ƒã áš¯áš¨ã‚áš·áš¦á›•áš¸á›¯á›„á›©á›‚áš²á›†á›áš°á›¨ã¼ã‚†á›‡á›®á›šáš¯á›“ã‚„áš¼ã‹áš¯áš¨á›¦á›«áš©áš²á›‹áš½ğŸ‘˜â™’ãœğŸ•‹ã‚”ğŸ•£ğŸ“¬ğŸ’Šâ˜ºğŸ¦Œ'),
            ('test11/metonymies.txt', 'á›ƒáš¬á›áš¸á›ˆáš¦áš±á›¦á›¢á›®áš¼á›‹áš¯á›¤áš³á›ˆá›“áš¿á›Šáš¬á›ˆáš¯á›áš¦á›…á›®áš§áš¬á›¦áš²áš®áš¶á›‘ãá›“á›”á›®ãá›˜áš¼á›¤áš©á›®áš¼á›‹á››á›¡áš±á›Œá›‘áš©á›ªãá›¤á›ƒá›…á›á›á›£áš¤áš»áš¦áš¢áš©á›¨á›á›˜ã‚”áš·áš´áš§ášºá›–á›‘á›¨á›ˆãŒá›ƒá›¥áš½á›šáš£á›‹áš¾áš³áš©ã”ã°áš©áš°ããŒãŸáš¨áš¼áš©á›‰ã‚œá›…áš¬áš²ã…ã—á›ªášµáš¨ãá›á›¡á›€ã”ã§á›Ÿáš¸ã‚–ãã‡ãŒğŸŸğŸƒã˜ã‚”áš«ã´ğŸ’ŒğŸ”¸ğŸ˜–á›†á›ªáš¯á›«áš¤á›‘ášºáš¾á›’á›¦ã«ã¼ã‚™ãã‚ƒã›ã­ã­ãª'),
            ('test12/incipience.txt', 'sereeeeeesssssssã‚Šáš·á›ˆáš³áš½áš¿ášªá›™á›ªá›„áš©áš¿á›¨áš§áš®ã‚ã‚á›‚á›†á›˜á›¤á›¤á›œá›‰á›ˆáš£ã®ã½áš³á›…ášºá›Šá››ášªáš¶áš¡á›˜áš·áš¥á›‘á›¬á›‹áš¥áš©áš®á›á›…á›áš¯áš±áš½ã—áš»á›”áš³á›‡ášªá›…áš²ášªá›¨á›’ã‚áš¨áš°áš½áš©áš¿ã¤ã’á›Šã¤áš¢ã á›‡ášºá›¯áš®ã‚Šáš¬áš´áš¹ã‚ˆã‚‡ã¬ãŠáš±á›®á›áš¹á›‘áš®ã£á›‹ğŸ›¢áš²á›¢ğŸ“²ãƒáš­á›¡ã‚ã´ğŸ†–ğŸ«’â°ğŸ‘¹ğŸ¹á›…ââ—€ğŸ›„ğŸ‘ğŸŒ½ğŸ”¥ğŸ…ğŸ†™ğŸ¦’ğŸ¦ŸğŸ”¤ğŸš“ğŸ˜—ğŸ˜•á›¦á›ƒá›®á›ˆá›‚'),)
    for key, value in datas:
        most = most_frequent_chars(key)
        print(f"{most}\n{value}\n{most == value}")
    pass
